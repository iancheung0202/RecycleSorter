<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width">
    <title>RecycleSorter</title>
    <style>
        @font-face {
            font-family: nougat;
            src: url(Nougat-ExtraBlack.ttf);
        }
		body {
            font-family: nougat;
			margin: 0;
			position: absolute;
			top: 50%;
			left: 50%;
			transform: translate(-50%, -50%);
            background-color: black;
            color: white;
		}
		#title {
            font-size: 50px;
        }
        .btn {
            justify-content: center;
            font-size: 30px;
            border: 1px solid white;
            padding: 10px;
            border-radius: 5px;
            transition: .2s;
            display: inline;
            margin-top: 100px;
            margin-bottom: 100px;
        }
        .btn:hover {
            background-color: white;
            color: black;
            cursor: pointer;
        }
        canvas {
            border-radius: 10px;
            margin-bottom: 50px;
        }
        #label-container {
            margin-top: 30px;
        }
    </style>
</head>

<body>
    <div id="startScreen">
        <div id="title"><h1>RecycleSorter</h1></div>
        <span class="btn" onclick="init('environment')">Start Sorting</span>
    </div>
    <div id="sortScreen" style="visibility: hidden; display: none;">
        <div id="webcam-container"></div>
        <div id="sortBtn"></div>
        <div id="label-container"></div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
    <script type="text/javascript">
        startScreen = document.getElementById("startScreen");
        sortScreen = document.getElementById("sortScreen");

        // More API functions here:
        // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

        // the link to your model provided by Teachable Machine export panel
        const URL = "https://teachablemachine.withgoogle.com/models/CgTV5zJeZ/";

        let model, webcam, labelContainer, maxPredictions;

        // Load the image model and setup the webcam
        async function init(arg) {

            while(document.getElementById("webcam-container").firstChild) {
                document.getElementById("webcam-container").removeChild(document.getElementById("webcam-container").firstChild);
            }

            startScreen.style.visibility = "hidden";
            startScreen.style.display = "none";
            sortScreen.style.visibility = "visible";
            sortScreen.style.display = "block";

            const modelURL = URL + "model.json";
            const metadataURL = URL + "metadata.json";

            // load the model and metadata
            // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
            // or files from your local hard drive
            // Note: the pose library adds "tmImage" object to your window (window.tmImage)
            model = await tmImage.load(modelURL, metadataURL);
            maxPredictions = model.getTotalClasses();

            // Convenience function to setup a webcam
            // const isMobile = navigator.userAgentData.mobile;
            // console.log(isMobile);
            // if (isMobile) {
            //     alert("You are using mobile!");
            // }
            const flip = false;
            var next = 'self';
            // if (isMobile) {
            //     flip = false;
            // } 
            webcam = new tmImage.Webcam(300, 300, flip); // width, height, flip
            if (arg == 'environment') {
                await webcam.setup({facingMode: "environment"}); // request access to the webcam
                
            } else if (arg == 'self') {
                await webcam.setup();
                next = 'environment';
            }
            await webcam.play();
            window.requestAnimationFrame(loop);

            // append elements to the DOM
            document.getElementById("webcam-container").appendChild(webcam.canvas);
            document.getElementById("sortBtn").innerHTML = `<span class="btn" id="sortBtn" onclick="predict()">Sort</span>&nbsp;&nbsp;&nbsp;<span class="btn" id="flipCamera" onclick="init('${next}')">Flip Camera</span>`
            labelContainer = document.getElementById("label-container");
            for (let i = 0; i < maxPredictions; i++) { // and class labels
                labelContainer.appendChild(document.createElement("div"));
            }
        }

        async function loop() {
            webcam.update(); // update the webcam frame
            // await predict();
            window.requestAnimationFrame(loop);
        }

        // run the webcam image through the image model
        // async function predict() {
        //     // predict can take in an image, video or canvas html element
        //     const prediction = await model.predict(webcam.canvas);
        //     for (let i = 0; i < maxPredictions; i++) {
        //         const classPrediction =
        //             prediction[i].className + ": " + prediction[i].probability.toFixed(2);
        //         labelContainer.childNodes[i].innerHTML = classPrediction;
        //     }
        // }
        async function predict() {
            // predict can take in an image, video or canvas html element
            const prediction = await model.predict(webcam.canvas);
            const probabilities = [];
            for (let i = 0; i < maxPredictions; i++) {
                const classPrediction =
                    probabilities.push(prediction[i].probability)
            }
            largestProbability = Math.max.apply(Math, probabilities)
            const index = probabilities.indexOf(largestProbability);
            labelContainer.innerHTML = prediction[index].className + ": " + prediction[index].probability.toFixed(2)*100 + "%";;
        }
    </script>

</body>
</html>
